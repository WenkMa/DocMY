## Mamba-YOLO: Multi-Level Adaptive Rectangular Convolution for Document Layout Analysis
ğŸ‘‰ [Click here to view the English instructions](./README.md)
## ä»‹ç»

â€‹	æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºä¸­æ–‡å¤šç§ç±»æ–‡æ¡£çš„ç‰ˆé¢åˆ†ææ•°æ®é›†å’Œä¸€ç§æ–°é¢–çš„ç‰ˆé¢åˆ†ææ–¹æ³•ã€‚åœ¨æ•°æ®é›†æ–¹é¢ï¼Œæˆ‘ä»¬å°†ç°æœ‰å·¥ä½œä¸­çš„â€˜Titleâ€™ç±»åˆ«è¿›è¡Œç»†åŒ–ï¼ŒåŒæ—¶å¼•å…¥äº†å¤šä¸ªç»†ç²’åº¦ä¸‹çš„æ ‡é¢˜ç±»åˆ«ä¿¡æ¯ï¼›å…¶æ¬¡æˆ‘ä»¬å°†å›¾ç‰‡ï¼Œè¡¨æ ¼å’Œå…¬å¼çš„æ ‡æ³¨èŒƒå›´è¿›è¡Œè°ƒæ•´ï¼Œä½¿å…¶èƒ½å¤Ÿè¦†ç›–å¯¹åº”çš„æè¿°ä¿¡æ¯æˆ–è€…å…¬å¼åºå·ã€‚åœ¨æ¨¡å‹æ–¹æ³•æ–¹é¢ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åŸºäºYOLOv9æ¡†æ¶ï¼Œå¼•å…¥Mambaç»“æ„å’Œå¤šå±‚è‡ªé€‚åº”çŸ©å½¢å·ç§¯æ–¹æ³•ï¼Œæœ‰æ•ˆçš„æå‡äº†æ–‡æ¡£ç‰ˆé¢åˆ†æçš„å·¥ä½œã€‚

â€‹	æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç°æœ‰å·¥ä½œä¸­ï¼Œç›¸è¾ƒäºYOLOv9æœ‰äº†ä¸€å®šçš„æ€§èƒ½æå‡ï¼Œä½†æ˜¯è·ç¦»SOTAä»ç„¶æœ‰æ”¹è¿›ç©ºé—´ã€‚

â€‹	æˆ‘ä»¬å°†ä¼šæŒç»­å‘å¸ƒæœ€æ–°çš„èµ„è®¯å’Œæ›´æ–°çš„æƒé‡ä¿¡æ¯ï¼Œä»¥åŠæˆ‘ä»¬æœ€æ–°çš„ç ”ç©¶æˆæœã€‚

## ç¯å¢ƒé…ç½®

### 1. Installation

DocMY is developed based on `torch==2.1.0` `transformers==4.49.0` and `CUDA Version==11.8`

### 2.Clone Project

```
git clone https://github.com/WenkMa/DocMY.git
```

### 3.Create and activate a conda environment.

```
conda create -n DocMY -y python=3.10
conda activate DocMY
```

### 4.Install torch

```
conda install pytorch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 pytorch-cuda=11.8 -c pytorch -c nvidia
```

### 5.å…¶ä»–ç¯å¢ƒ

å…¶ä»–ç¯å¢ƒå‚è€ƒYOLOv9ä¸­ç¯å¢ƒ

## æ•°æ®é›†ä»‹ç»

**PeKi**ä¸»è¦åŒ…å«åå››ç§æ–‡æ¡£ç‰ˆé¢åˆ†æçš„ç±»åˆ«ï¼Œä¸»è¦æœ‰ï¼š

Formula, Formula-Num, Figure, Figure-Caption, Reference, Table, Table-Caption, Footer, Header, Doc-Title, Title-Id, Title-NoId, Title-Body, Title-Last.

æˆ‘ä»¬å…¬å¼€äº†æˆ‘ä»¬è®ºæ–‡ä¸­çš„ç›¸å…³æ•°æ®é›†[PeKi](https://huggingface.co/datasets/Mwk19990801/PeKi)ç¤ºä¾‹ï¼Œå¯ä»¥ä¾›ç”¨æˆ·æ›´å¥½çš„å»äº†è§£æˆ‘ä»¬è¯¦ç»†çš„å†…å®¹ã€‚

å¦‚æœæƒ³è¦æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œè¯·å°†ç”³è¯·æŠ¥å‘Šå‘é€è‡³é‚®ç®±ï¼Œæˆ‘ä»¬æ”¶åˆ°åå°†ä¼šä¸æ‚¨è”ç³»ã€‚

## è®­ç»ƒè¿‡ç¨‹

Multiple GPU training

```
# train DocMY models
python -m torch.distributed.launch --nproc_per_node 4 --master_port 9527 train_dual.py --workers 4 --device 0,1,2,3 --sync-bn --batch -1 --data data/peki.yaml --img 640 --cfg models/detect/DocMY.yaml --weights '' --name DocMY --hyp hyp.scratch-high.yaml --min-items 0 --epochs 100 --close-mosaic 15
```

## éªŒè¯è¿‡ç¨‹

```
# evaluate converted yolov9 models
python val.py --data data/peki.yaml --img 640 --batch 8 --conf 0.001 --iou 0.7 --device 0 --weights './DocMY.pt' --save-json --name yolov9_peki_val
```

## æ¨ç†è¿‡ç¨‹

```
# inference converted yolov9 models
python detect.py --source './data/document/notice.jpg' --img 640 --device 0 --weights './DocMY.pt' --name yolov9_peki_detect
```

æˆ‘ä»¬åŒæ—¶è¿˜å…¬å¸ƒäº†æˆ‘ä»¬ä½¿ç”¨YOLOv9è®­ç»ƒåçš„æ¨¡å‹æƒé‡å’Œä»£ç ï¼Œå¯ä»¥å‚è€ƒyolov9-onnxruntimeä¸­çš„å†…å®¹ï¼Œå¹¶å®Œæˆäº†æœåŠ¡ç«¯å’Œè¯·æ±‚ç«¯çš„ä»£ç ä¿¡æ¯ã€‚

## TODO

1.éªŒè¯ä¸åŒæ¨¡å‹åœ¨å…¶ä»–å¼€æºæ•°æ®é›†çš„å®éªŒï¼Œæ›´å¥½çš„è¡¥å……æˆ‘ä»¬æ–‡ç« ã€‚

- [ ] PubLayNet
- [ ] CDLA
- [ ] D4LA
- [ ] DocLayNet

2.æˆ‘ä»¬æ­£åœ¨æ”¶é›†å¹¶è¿›è¡Œæ ‡æ³¨æ›´å¤šçš„æ–‡æ¡£ç‰ˆé¢åˆ†ææ•°æ®é›†ï¼Œå°†ä¼šåŠæ—¶çš„åœ¨æœ¬åœ°å…¬å¸ƒå¹¶æ›´æ–°æ•°æ®é›†ç½‘å€ã€‚

## Acknowledgement

This repo is modified from open source real-time object detection codebase [Ultralytics](https://github.com/ultralytics/ultralytics), [Mamba-YOLO](https://github.com/HZAI-ZJNU/Mamba-YOLO) and [VMamba](https://github.com/MzeroMiko/VMamba). The selective-scan from [Mamba](https://github.com/state-spaces/mamba).
