## Mamba-YOLO: Multi-Level Adaptive Rectangular Convolution for Document Layout Analysis

ğŸ‘‰ [Click here to view the English instructions](./README.md)

## ä»‹ç»

â€‹	æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºä¸­æ–‡å¤šç§ç±»æ–‡æ¡£çš„ç‰ˆé¢åˆ†ææ•°æ®é›†å’Œä¸€ç§æ–°é¢–çš„ç‰ˆé¢åˆ†ææ–¹æ³•ã€‚åœ¨æ•°æ®é›†æ–¹é¢ï¼Œæˆ‘ä»¬å°†ç°æœ‰å·¥ä½œä¸­çš„â€˜Titleâ€™ç±»åˆ«è¿›è¡Œç»†åŒ–ï¼ŒåŒæ—¶å¼•å…¥äº†å¤šä¸ªç»†ç²’åº¦ä¸‹çš„æ ‡é¢˜ç±»åˆ«ä¿¡æ¯ï¼›å…¶æ¬¡æˆ‘ä»¬å°†å›¾ç‰‡ï¼Œè¡¨æ ¼å’Œå…¬å¼çš„æ ‡æ³¨èŒƒå›´è¿›è¡Œè°ƒæ•´ï¼Œä½¿å…¶èƒ½å¤Ÿè¦†ç›–å¯¹åº”çš„æè¿°ä¿¡æ¯æˆ–è€…å…¬å¼åºå·ã€‚åœ¨æ¨¡å‹æ–¹æ³•æ–¹é¢ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åŸºäºYOLOv9æ¡†æ¶ï¼Œå¼•å…¥Mambaç»“æ„å’Œå¤šå±‚è‡ªé€‚åº”çŸ©å½¢å·ç§¯æ–¹æ³•ï¼Œæœ‰æ•ˆçš„æå‡äº†æ–‡æ¡£ç‰ˆé¢åˆ†æçš„å·¥ä½œã€‚

â€‹	æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç°æœ‰å·¥ä½œä¸­ï¼Œç›¸è¾ƒäºYOLOv9æœ‰äº†ä¸€å®šçš„æ€§èƒ½æå‡ï¼Œä½†æ˜¯è·ç¦»SOTAä»ç„¶æœ‰æ”¹è¿›ç©ºé—´ã€‚

â€‹	æˆ‘ä»¬å°†ä¼šæŒç»­å‘å¸ƒæœ€æ–°çš„èµ„è®¯å’Œæ›´æ–°çš„æƒé‡ä¿¡æ¯ï¼Œä»¥åŠæˆ‘ä»¬æœ€æ–°çš„ç ”ç©¶æˆæœã€‚

## ç¯å¢ƒé…ç½®

### 1. Installation

DocMY is developed based on `torch==2.1.0` `transformers==4.49.0` and `CUDA Version==11.8`

### 2.Clone Project

```
git clone https://github.com/WenkMa/DocMY.git
```

### 3.Create and activate a conda environment.

```
conda create -n DocMY -y python=3.10
conda activate DocMY
```

### 4.Install torch

```
conda install pytorch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 pytorch-cuda=11.8 -c pytorch -c nvidia
```

### 5.å…¶ä»–ç¯å¢ƒ

å…¶ä»–ç¯å¢ƒå‚è€ƒYOLOv9ä¸­ç¯å¢ƒ

## æ•°æ®é›†ä»‹ç»

**PeKi**ä¸»è¦åŒ…å«åå››ç§æ–‡æ¡£ç‰ˆé¢åˆ†æçš„ç±»åˆ«ï¼Œä¸»è¦æœ‰ï¼š

Formula, Formula-Num, Figure, Figure-Caption, Reference, Table, Table-Caption, Footer, Header, Doc-Title, Title-Id, Title-NoId, Title-Body, Title-Last.

æˆ‘ä»¬å…¬å¼€äº†æˆ‘ä»¬è®ºæ–‡ä¸­çš„ç›¸å…³æ•°æ®é›†[PeKi](https://huggingface.co/datasets/Mwk19990801/PeKi)ç¤ºä¾‹ï¼Œå¯ä»¥ä¾›ç”¨æˆ·æ›´å¥½çš„å»äº†è§£æˆ‘ä»¬è¯¦ç»†çš„å†…å®¹ã€‚

å¦‚æœæƒ³è¦æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œè¯·å°†ç”³è¯·æŠ¥å‘Šå‘é€è‡³é‚®ç®±ï¼Œæˆ‘ä»¬æ”¶åˆ°åå°†ä¼šä¸æ‚¨è”ç³»ã€‚

## è®­ç»ƒè¿‡ç¨‹

Multiple GPU training

```
# train DocMY models
python -m torch.distributed.launch --nproc_per_node 4 --master_port 9527 train_dual.py --workers 4 --device 0,1,2,3 --sync-bn --batch -1 --data /path/to/yaml --img 640 --cfg /path/to/yaml --weights '' --name DocMY --hyp hyp.scratch-high.yaml --min-items 0 --epochs 100 --close-mosaic 15
```

## éªŒè¯è¿‡ç¨‹

```
# evaluate converted yolov9 models
python val.py --data /path/to/yaml --img 640 --batch 8 --conf 0.001 --iou 0.7 --device 0 --weights /path/to/weights --save-json --name yolov9_peki_val
```

## æ¨ç†è¿‡ç¨‹

```
# inference converted yolov9 models
python detect.py --source /path/to/image --img 640 --device 0 --weights /path/to/weights --name yolov9_peki_detect
```

æˆ‘ä»¬åŒæ—¶è¿˜å…¬å¸ƒäº†æˆ‘ä»¬ä½¿ç”¨YOLOv9è®­ç»ƒåçš„æ¨¡å‹æƒé‡å’Œä»£ç ï¼Œå¯ä»¥å‚è€ƒyolov9-onnxruntimeä¸­çš„å†…å®¹ï¼Œå¹¶å®Œæˆäº†æœåŠ¡ç«¯å’Œè¯·æ±‚ç«¯çš„ä»£ç ä¿¡æ¯ã€‚

## TODO

1.éªŒè¯ä¸åŒæ¨¡å‹åœ¨å…¶ä»–å¼€æºæ•°æ®é›†çš„å®éªŒï¼Œæ›´å¥½çš„è¡¥å……æˆ‘ä»¬æ–‡ç« ã€‚

- [x] PubLayNet

- [x] CDLA

- [x] D4LA

- [x] DocLayNet

  | Datasets  | Method      | P(%)       | R(%)       | mAP50(%)   | mAP50-95(%) |
  | --------- | ----------- | ---------- | ---------- | ---------- | ----------- |
  | PubLayNet | VGT(SOTA)   | -          | -          | 98.1       | 96.2        |
  |           | Layoutlmv3  | -          | -          | 98.1       | 95.1        |
  |           | DiT         | -          | -          | 97.9       | 93.8        |
  |           | YOLOv9      | 87.2       | 86.5       | 88.1       | 83.1        |
  |           | VMamba      | 97.4       | 95.3       | 97.9       | 90.8        |
  |           | DocMY(ours) | 92.4(+5.2) | 91.5(+5.0) | 93.3(+5.2) | 88.4(+5.3)  |
  | CDLA      | Layoutlmv3  | -          | -          | 66.9       | 47.0        |
  |           | YOLOv5      | 91.5       | 85.7       | 91.9       | 66.6        |
  |           | YOLOv8      | 90.2       | 88.2       | 93.8       | 77.2        |
  |           | YOLOv9      | 90.1       | 87.4       | 94.0       | 77.3        |
  |           | VMamba      | 89.5       | 88.0       | 93.5       | 78.3        |
  |           | DocMY(ours) | 93.2(+2.2) | 91.4(+4.0) | 96.1(+2.1) | 83.3(+6.0)  |
  | DocLayNet | GLAM(SOTA)  | -          | -          | -          | 80.8        |
  |           | Layoutlmv3  | -          | -          | 90.2       | 72.6        |
  |           | YOLOv9      | 88.5       | 81.8       | 89.6       | 69.8        |
  |           | VMamba      | 88.6       | 84.0       | 91.1       | 69.8        |
  |           | DocMY(ours) | 89.5(+1.0) | 81.8       | 90.2(+0.6) | 70.9(+1.1)  |
  | D4LA      | VGT(SOTA)   | -          | -          | 81.9       | 68.8        |
  |           | Layoutlmv3  | -          | -          | 75.2       | 61.9        |
  |           | YOLOv9      | 75.1       | 64.1       | 69.8       | 56.0        |
  |           | VMamba      | 77.4       | 66.4       | 71.7       | 57.8        |
  |           | DocMY(ours) | 77.8(+2.7) | 71.7(+7.6) | 76.7(+6.9) | 62.8(+6.8)  |

  Effects of Our Method on PubLayNet, CDLA, DocLayNet, and D4LA. Bold indicates performance improvement compared to baseline YOLOv9. - indicates that we did not find or reproduce the result.

2.æˆ‘ä»¬å·²ç»æ”¶é›†äº†æ›´å¤šçš„è¯­è¨€çš„æ–‡æ¡£ï¼Œæ­£åœ¨è¿›è¡Œæ ‡æ³¨ã€‚åŒæ—¶æˆ‘ä»¬ä¹Ÿå°†æˆ‘ä»¬æœ€æ–°çš„æƒé‡ä¸Šä¼ åˆ°äº†Hugging Faceã€‚æˆ‘ä»¬ä¼šåŠæ—¶æ›´æ–°æˆ‘ä»¬çš„å·¥ä½œè¿›å±•ã€‚

## Acknowledgement

This repo is modified from open source real-time object detection codebase [Ultralytics](https://github.com/ultralytics/ultralytics), [Mamba-YOLO](https://github.com/HZAI-ZJNU/Mamba-YOLO), [VMamba](https://github.com/MzeroMiko/VMamba) and [Unlim](https://github.com/microsoft/unilm). The selective-scan from [Mamba](https://github.com/state-spaces/mamba).
